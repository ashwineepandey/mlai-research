{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../mlai_research/')\n",
    "import log\n",
    "import utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.filters import threshold_sauvola\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from rasterio.mask import mask\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13-Dec-23 01:21:26 - INFO - Starting 'load_config'.\n",
      "13-Dec-23 01:21:26 - INFO - Finished 'load_config' in 0.0509 secs.\n"
     ]
    }
   ],
   "source": [
    "logger = log.get_logger(__name__)\n",
    "conf = utils.load_config('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgb_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        images.append(img_rgb)\n",
    "    return np.array(images)\n",
    "\n",
    "def load_grayscale_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "def plot_cropped_images(images, titles, ncols=3):\n",
    "    \"\"\"Plot a list of loaded images.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of loaded images.\n",
    "        titles (list): List of titles for the images.\n",
    "        ncols (int): Number of columns for the subplot grid.\n",
    "    \"\"\"\n",
    "    nrows = len(images) // ncols + (len(images) % ncols > 0) # calculate number of rows\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.suptitle('Cropped Images', fontsize=18, y=0.95)\n",
    "\n",
    "    for n, img in enumerate(images):\n",
    "        # add a new subplot iteratively using nrows and cols\n",
    "        ax = plt.subplot(nrows, ncols, n + 1)\n",
    "        # Plot raster crop\n",
    "        ax.imshow(img)\n",
    "        # chart formatting\n",
    "        ax.set_title(os.path.basename(titles[n]), fontsize=8)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def normalize_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes the pixel values of the input image to the range 0-255.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The normalized image.\n",
    "    \"\"\"\n",
    "    normalized_image = ((image - np.min(image)) / (np.max(image) - np.min(image))) * 255\n",
    "    return normalized_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_fns = utils.get_filenames(\"../data/02_intermediate/04_cropped_imgs/\", \"png\", 'rgb')\n",
    "# chm_fns = utils.get_filenames(\"../data/02_intermediate/04_cropped_imgs/\", \"png\", 'chm')\n",
    "rgb_imgs = load_rgb_images(rgb_fns[:9])\n",
    "# chm_imgs = load_grayscale_images(chm_fns[:-9])\n",
    "# plot_cropped_images(rgb_imgs[:9], rgb_fns[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_masked_images(normalized_image, segmented_image, masked_image):\n",
    "    # Set up the plot with 4 columns\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "\n",
    "    # for i in range(num_images):\n",
    "    # Plot the normalized image in the first column\n",
    "    axes[0].imshow(normalized_image)\n",
    "    axes[0].set_title('Normalized Image')\n",
    "\n",
    "    # Plot the processed image with boundaries in the third column\n",
    "    axes[1].imshow(mark_boundaries(normalized_image, segmented_image))\n",
    "    axes[1].set_title('Segmented Image')\n",
    "\n",
    "    # Plot the masked image in the fourth column\n",
    "    axes[2].imshow(masked_image)\n",
    "    axes[2].set_title('Masked Image')\n",
    "\n",
    "    # Adjust layout to prevent clipping of titles\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_center_segment_mask(segmentation, image_shape):\n",
    "    # Step 1: Identify the center point of the image\n",
    "    center_point = (image_shape[0] // 2, image_shape[1] // 2)\n",
    "\n",
    "    # Step 2: Identify the segment label at the center point\n",
    "    center_segment_label = segmentation[center_point]\n",
    "\n",
    "    # Step 3: Create a mask by comparing the segmentation array with the center segment label\n",
    "    mask = segmentation == center_segment_label\n",
    "\n",
    "    # Step 4: Zero out all other segments by multiplying the original image with the mask\n",
    "    # This step would be done outside this function, when you have the original image available\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def color_based_segment_mask(segments, image):\n",
    "    # Convert segments to a binary image\n",
    "    mask = (segments > 0).astype('uint8')\n",
    "\n",
    "    # Calculate the average color of each segment\n",
    "    avg_colors = cv2.mean(image, mask=mask)\n",
    "\n",
    "    # Convert the average colors to a numpy array of the same size as the color boundaries\n",
    "    avg_colors = np.array(avg_colors[:3])\n",
    "\n",
    "    # Define the color range for bushes or shrubs\n",
    "    lower_color = np.array([25., 50., 50.])\n",
    "    upper_color = np.array([85., 255., 255.])\n",
    "\n",
    "    # Keep the segments that fall within the color range\n",
    "    mask = cv2.inRange(avg_colors, lower_color, upper_color)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def texture_based_segment_mask(segments, image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the Local Binary Pattern of the image\n",
    "    lbp = feature.local_binary_pattern(gray, P=8, R=1)\n",
    "    \n",
    "    # Convert segments_fz to a binary image\n",
    "    mask = (segments > 0).astype('uint8') * 255\n",
    "\n",
    "    # Now use this mask in cv2.mean\n",
    "    avg_lbp = cv2.mean(lbp, mask=mask)\n",
    "    # # Calculate the average LBP of each segment\n",
    "    # avg_lbp = cv2.mean(lbp, mask=segments)\n",
    "\n",
    "    # Define the LBP range for bushes or shrubs\n",
    "    lower_lbp = 0.2\n",
    "    upper_lbp = 0.8\n",
    "\n",
    "    # Keep the segments that fall within the LBP range\n",
    "    mask = (avg_lbp >= lower_lbp) & (avg_lbp <= upper_lbp)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def apply_mask(image, mask):\n",
    "    # Ensure mask is boolean\n",
    "    mask = mask.astype(bool)\n",
    "    \n",
    "    # Expand dimensions of the mask to match the image\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    masked_image = image * mask\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "def apply_color_mask(image, mask):\n",
    "    # Ensure mask is boolean\n",
    "    mask = mask.astype(bool)\n",
    "    \n",
    "    # Repeat the mask along its missing dimensions\n",
    "    # Expand dimensions of the mask to match the image\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.repeat(mask, image.shape[-1], axis=-1)\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    masked_image = image * mask\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (87,87,3) (3,1,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# mask = create_center_segment_mask(segments_fz, rgb_img.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mask \u001b[39m=\u001b[39m color_based_segment_mask(segments_fz, rgb_img)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m masked_image \u001b[39m=\u001b[39m apply_color_mask(rgb_img, mask)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# mask = texture_based_segment_mask(segments_fz, rgb_img)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# masked_image = apply_mask(rgb_img, mask)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m plot_masked_images(rgb_img, segments_fz, masked_image)\n",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(mask, image\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# Apply the mask to the image\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m masked_image \u001b[39m=\u001b[39m image \u001b[39m*\u001b[39;49m mask\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/notebooks/explore-segmentation-008.ipynb#X12sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mreturn\u001b[39;00m masked_image\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (87,87,3) (3,1,3) "
     ]
    }
   ],
   "source": [
    "rgb_img = normalize_image(rgb_imgs[3])\n",
    "segments_fz = felzenszwalb(rgb_img, scale=150, sigma=0.5, min_size=100)\n",
    "# mask = create_center_segment_mask(segments_fz, rgb_img.shape)\n",
    "mask = color_based_segment_mask(segments_fz, rgb_img)\n",
    "masked_image = apply_color_mask(rgb_img, mask)\n",
    "# mask = texture_based_segment_mask(segments_fz, rgb_img)\n",
    "# masked_image = apply_mask(rgb_img, mask)\n",
    "plot_masked_images(rgb_img, segments_fz, masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert segments to a binary image\n",
    "mask = (segments_fz > 0).astype('uint8')\n",
    "\n",
    "# Calculate the average color of each segment\n",
    "avg_colors = cv2.mean(rgb_img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146.4718719002409, 146.66246280289076, 100.59713759387841, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_colors = np.array(avg_colors[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146.4718719 , 146.6624628 , 100.59713759])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_color = np.array([25., 50., 50.])\n",
    "upper_color = np.array([85., 255., 255.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25., 50., 50.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.inRange(avg_colors, lower_color, upper_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot_chm(chm_path):\n",
    "    \"\"\"Load and plot a Canopy Height Model (CHM) from a TIFF file.\n",
    "    \n",
    "    Args:\n",
    "        chm_path (str): Path to the CHM TIFF file.\n",
    "    \"\"\"\n",
    "    # Open the file using rasterio\n",
    "    with rasterio.open(chm_path) as chm_dataset:\n",
    "        # Read the CHM data into a 2D array\n",
    "        chm_data = chm_dataset.read(1)\n",
    "        \n",
    "    # Plot the CHM data\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    rasterio.plot.show(chm_data, cmap='gray')\n",
    "    plt.title('Canopy Height Model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_path = '../data/02_intermediate/03_cropped_tifs/283_rgb_Xanthium.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes the pixel values of the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The normalized image.\n",
    "    \"\"\"\n",
    "    normalized_image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return normalized_image\n",
    "\n",
    "def load_dsm_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the image in grayscale mode\n",
    "    return img\n",
    "\n",
    "def plot_dsm_image(image):\n",
    "    plt.imshow(image, cmap='gray')  # Use a grayscale colormap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_image = load_dsm_image(dsm_path)\n",
    "normalized_dsm_image = normalize_image(dsm_image)\n",
    "plot_dsm_image(normalized_dsm_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(chm_path) as dst:\n",
    "        # Read the CHM data into a 2D array\n",
    "        dsm_data = dst.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.min(dsm_data)\n",
    "max_value = np.max(dsm_data)\n",
    "mean_value = np.mean(dsm_data)\n",
    "min_value, max_value, mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to 0-1 range\n",
    "dsm_data_norm = (dsm_data - np.min(dsm_data)) / (np.max(dsm_data) - np.min(dsm_data))\n",
    "\n",
    "# Plot the normalized data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(dsm_data_norm, cmap='gray')\n",
    "plt.colorbar(label='Normalized Values')\n",
    "plt.title('Normalized DSM Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_and_plot_chm(chm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_img = rasterio.open(f\"../data/02_intermediate/03_cropped_tifs/279_chm_Xanthium.tif\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_data = chm_img.read(1)\n",
    "chm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "rasterio.plot.show(chm_data, cmap='viridis')\n",
    "plt.title('Canopy Height Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.min(chm_img)\n",
    "max_value = np.max(chm_img)\n",
    "min_value, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cropped_tifs(path):\n",
    "    return glob.glob(f'{path}*.tif')\n",
    "\n",
    "def normalize_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes the pixel values of the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The normalized image.\n",
    "    \"\"\"\n",
    "    normalized_image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    logger.info(f'Normalized image shape: {normalized_image.shape}')\n",
    "    return normalized_image\n",
    "\n",
    "def process_rgb_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts the RGB channels from the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The RGB image.\n",
    "    \"\"\"\n",
    "    # Add your RGB processing logic here\n",
    "    img_rgb = image[:, :, :3]\n",
    "    logger.info(f'RGB image shape: {img_rgb.shape}')\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def get_segments(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs segmentation on the input image using the Felzenszwalb algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The segmented image.\n",
    "    \"\"\"\n",
    "    # Add your segmentation logic here\n",
    "    segments_fz = felzenszwalb(image, scale=100, sigma=0.5, min_size=50)\n",
    "    return segments_fz\n",
    "\n",
    "# def segment_image(image: np.ndarray) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Segments the input image to extract plant regions based on color.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "#     Returns:\n",
    "#     - numpy.ndarray: The segmented image containing only plant regions.\n",
    "#     \"\"\"\n",
    "#     # Convert the image from RGB to HSV\n",
    "#     hsv_image = rgb2hsv(image)\n",
    "    \n",
    "#     # Define the color range for the plants\n",
    "#     lower_green = np.array([35/360, 0.2, 0.2])\n",
    "#     upper_green = np.array([85/360, 1, 1])\n",
    "    \n",
    "#     # Create a mask for the plant segments\n",
    "#     plant_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    \n",
    "#     # Apply the mask to the image\n",
    "#     plant_segments = cv2.bitwise_and(image, image, mask=plant_mask)\n",
    "    \n",
    "#     return plant_segments\n",
    "\n",
    "# def segment_image(image: np.ndarray) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Segments the input image to extract plant regions using adaptive thresholding.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "#     Returns:\n",
    "#     - numpy.ndarray: The segmented image containing only plant regions.\n",
    "#     \"\"\"\n",
    "#     # Convert the image from RGB to HSV\n",
    "#     hsv_image = rgb2hsv(image)\n",
    "\n",
    "#     # Convert the HSV image to grayscale\n",
    "#     gray_image = cv2.cvtColor(hsv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Convert the grayscale image to 8-bit unsigned integer\n",
    "#     gray_image = np.uint8(gray_image)\n",
    "\n",
    "#     # Apply adaptive thresholding (Otsu's method)\n",
    "#     _, plant_mask = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "#     # Create a mask with the same number of channels as the input image\n",
    "#     plant_mask_rgb = cv2.cvtColor(plant_mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "#     # Ensure the mask has the correct data type and size\n",
    "#     plant_mask_rgb = np.uint8(plant_mask_rgb)\n",
    "\n",
    "#     # Apply the mask to the original image\n",
    "#     plant_segments = cv2.bitwise_and(image, image, mask=plant_mask_rgb)\n",
    "\n",
    "#     return plant_segments\n",
    "\n",
    "def rgb2hsv(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts an RGB image to HSV.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The converted HSV image.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "\n",
    "def segment_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Segments the input image to extract plant regions using adaptive thresholding.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The segmented image containing only plant regions.\n",
    "    \"\"\"\n",
    "    # Convert the image from RGB to HSV\n",
    "    hsv_image = rgb2hsv(image)\n",
    "\n",
    "    # # Extract the V channel from the HSV image\n",
    "    # v_channel = hsv_image[:, :, 2]\n",
    "\n",
    "    # Convert the HSV image to grayscale\n",
    "    gray_image = cv2.cvtColor(hsv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Scale the grayscale image from [0, 1] to [0, 255] and convert to uint8\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Apply adaptive thresholding (Gaussian method)\n",
    "    plant_mask = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Create a mask with the same number of channels as the input image\n",
    "    plant_mask_rgb = cv2.cvtColor(plant_mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Ensure the mask has the correct data type and size\n",
    "    # plant_mask_rgb = np.uint8(plant_mask_rgb)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    plant_segments = cv2.bitwise_and(image, image, mask=plant_mask_rgb)\n",
    "\n",
    "    return plant_segments\n",
    "\n",
    "\n",
    "def threshold_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies thresholding to the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The binary image after thresholding.\n",
    "    \"\"\"\n",
    "    # Add your thresholding logic here\n",
    "    thresh_sauvola = threshold_sauvola(image)\n",
    "    binary_sauvola = image > thresh_sauvola\n",
    "    return binary_sauvola\n",
    "\n",
    "# def apply_mask_to_segments(image, segments, plant_segment_ids):\n",
    "#     masked_image = np.zeros_like(image)\n",
    "#     for segment_id in plant_segment_ids:\n",
    "#         # Get the pixels of the segment\n",
    "#         segment_mask = (segments == segment_id)\n",
    "        \n",
    "#         # Apply the mask to the segment and store the result in the masked image\n",
    "#         masked_image[segment_mask] = image[segment_mask]\n",
    "    \n",
    "#     return masked_image\n",
    "\n",
    "def apply_mask_to_segments(image: np.ndarray, segments: np.ndarray, \n",
    "                            plant_segment_ids: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies a mask to specific segments in the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image.\n",
    "    - segments (numpy.ndarray): The segmentation map.\n",
    "    - plant_segment_ids (list): List of segment IDs corresponding to plant regions.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The masked image containing only the specified plant segments.\n",
    "    \"\"\"\n",
    "    masked_image = np.zeros_like(image)\n",
    "    \n",
    "    if len(plant_segment_ids) == 0:  # If no plant segments are found\n",
    "        # Calculate the sum of pixel values in each segment\n",
    "        segment_sums = [np.sum(image[segments == segment_id]) for segment_id in np.unique(segments)]\n",
    "        # Find the segment with the highest sum\n",
    "        max_segment_id = np.argmax(segment_sums)\n",
    "        # Add this segment to the plant_segment_ids\n",
    "        plant_segment_ids.append(max_segment_id)\n",
    "    \n",
    "    for segment_id in plant_segment_ids:\n",
    "        segment_mask = (segments == segment_id)\n",
    "        masked_image[segment_mask] = image[segment_mask]\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "def load_raster(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        # Read the data and transpose the dimensions\n",
    "        raster_data = src.read().transpose(1, 2, 0)\n",
    "    return raster_data\n",
    "\n",
    "def process_images(image_paths):\n",
    "    normalized_images = []\n",
    "    rgb_images = []\n",
    "    imgs_segments = []\n",
    "    masked_images = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        raster_data = load_raster(image_path)\n",
    "        logger.info(f'Raster data shape: {raster_data.shape}')\n",
    "\n",
    "        normalized_image = normalize_image(raster_data)\n",
    "        normalized_images.append(normalized_image)\n",
    "\n",
    "        rgb_image = process_rgb_image(normalized_image)\n",
    "        rgb_images.append(rgb_image)\n",
    "\n",
    "        segments = get_segments(rgb_image)\n",
    "        imgs_segments.append(segments)\n",
    "\n",
    "        plant_segments = segment_image(rgb_image)\n",
    "\n",
    "        # Replace 'plant_segment_ids' with the list of plant segment IDs\n",
    "        masked_image = apply_mask_to_segments(rgb_image, segments, [1])\n",
    "        masked_images.append(masked_image)\n",
    "\n",
    "    return normalized_images, rgb_images, imgs_segments, masked_images\n",
    "\n",
    "# def plot_images(normalized_images, rgb_images, segmented_images, masked_images):\n",
    "#     num_images = len(normalized_images)\n",
    "\n",
    "#     # Set up the plot with 4 columns\n",
    "#     fig, axes = plt.subplots(nrows=num_images, ncols=4, figsize=(16, 4*num_images))\n",
    "\n",
    "#     for i in range(num_images):\n",
    "#         # Plot the normalized image in the first column\n",
    "#         axes[i, 0].imshow(normalized_images[i])\n",
    "#         axes[i, 0].set_title('Normalized Image')\n",
    "\n",
    "#         # Plot the processed RGB image in the second column\n",
    "#         axes[i, 1].imshow(rgb_images[i])\n",
    "#         axes[i, 1].set_title('Processed RGB')\n",
    "\n",
    "#         # Plot the processed image with boundaries in the third column\n",
    "#         axes[i, 2].imshow(mark_boundaries(rgb_images[i], segmented_images[i]))\n",
    "#         axes[i, 2].set_title('Segmented Image')\n",
    "\n",
    "#         # Plot the masked image in the fourth column\n",
    "#         axes[i, 3].imshow(masked_images[i])\n",
    "#         axes[i, 3].set_title('Masked Image')\n",
    "\n",
    "#     # Adjust layout to prevent clipping of titles\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "def plot_all_rasters(normalized_images, rgb_images, segmented_images, masked_images):\n",
    "    num_images = len(normalized_images)\n",
    "\n",
    "    # Set up the plot with 4 columns\n",
    "    fig, axes = plt.subplots(nrows=num_images, ncols=4, figsize=(16, 4*num_images))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Plot the normalized image in the first column\n",
    "        axes[i, 0].imshow(normalized_images[i])\n",
    "        axes[i, 0].set_title('Normalized Image')\n",
    "\n",
    "        # Plot the processed RGB image in the second column\n",
    "        axes[i, 1].imshow(rgb_images[i])\n",
    "        axes[i, 1].set_title('Processed RGB')\n",
    "\n",
    "        # Plot the processed image with boundaries in the third column\n",
    "        axes[i, 2].imshow(mark_boundaries(rgb_images[i], segmented_images[i]))\n",
    "        axes[i, 2].set_title('Segmented Image')\n",
    "\n",
    "        # Plot the masked image in the fourth column\n",
    "        axes[i, 3].imshow(masked_images[i])\n",
    "        axes[i, 3].set_title('Masked Image')\n",
    "\n",
    "    # Adjust layout to prevent clipping of titles\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images(normalized_image, segmented_image, masked_image):\n",
    "    # Set up the plot with 4 columns\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 3))\n",
    "\n",
    "    # for i in range(num_images):\n",
    "    # Plot the normalized image in the first column\n",
    "    axes[0].imshow(normalized_image)\n",
    "    axes[0].set_title('Normalized Image')\n",
    "\n",
    "    # Plot the processed RGB image in the second column\n",
    "    # axes[1].imshow(rgb_image)\n",
    "    # axes[1].set_title('Processed RGB')\n",
    "\n",
    "    # Plot the processed image with boundaries in the third column\n",
    "    axes[1].imshow(mark_boundaries(normalized_image, segmented_image))\n",
    "    axes[1].set_title('Segmented Image')\n",
    "\n",
    "    # Plot the masked image in the fourth column\n",
    "    axes[2].imshow(masked_image)\n",
    "    axes[2].set_title('Masked Image')\n",
    "\n",
    "    # Adjust layout to prevent clipping of titles\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_fns_rgb = load_cropped_tifs(conf.data.path_pri_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_img = load_raster(cropped_fns_rgb[0])\n",
    "logger.info(f'Raster data shape: {raster_img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = process_rgb_image(raster_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_norm_img = normalize_image(rgb_img)\n",
    "rgb_not_norm_img = cv2.normalize(rgb_norm_img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = get_segments(rgb_norm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'image' is your ndarray\n",
    "min_value = np.min(rgb_img)\n",
    "max_value = np.max(rgb_img)\n",
    "min_value, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def segment_image(image: np.ndarray) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Segments the input image to extract plant regions using adaptive thresholding.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "#     Returns:\n",
    "#     - numpy.ndarray: The segmented image containing only plant regions.\n",
    "#     \"\"\"\n",
    "#     # Convert the image from RGB to HSV\n",
    "#     hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "#     # Extract the V channel from the HSV image\n",
    "#     v_channel = hsv_image[:, :, 2]\n",
    "\n",
    "#     # Scale the V channel from [0, 1] to [0, 255] and convert to uint8\n",
    "#     v_channel = (v_channel * 255).astype(np.uint8)\n",
    "\n",
    "#     # Apply adaptive thresholding (Gaussian method)\n",
    "#     plant_mask = cv2.adaptiveThreshold(v_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "#     # Create a mask with the same number of channels as the input image\n",
    "#     plant_mask_rgb = cv2.cvtColor(plant_mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "#     # Ensure the mask has the correct data type and size\n",
    "#     plant_mask_rgb = np.uint8(plant_mask_rgb)\n",
    "\n",
    "#     # Apply the mask to the original image\n",
    "#     plant_segments = cv2.bitwise_and(image, image, mask=plant_mask_rgb)\n",
    "\n",
    "#     return plant_segments\n",
    "\n",
    "# def segment_image(image: np.ndarray) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Segments the input image to extract plant regions using adaptive thresholding.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "#     Returns:\n",
    "#     - numpy.ndarray: The segmented image containing only plant regions.\n",
    "#     \"\"\"\n",
    "#     # Convert the image from RGB to HSV\n",
    "#     hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "#     # Extract the V channel from the HSV image\n",
    "#     v_channel = hsv_image[:, :, 2]\n",
    "\n",
    "#     # Apply adaptive thresholding (Gaussian method)\n",
    "#     plant_mask = cv2.adaptiveThreshold(v_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "#     # Apply the mask to the original image\n",
    "#     plant_segments = cv2.bitwise_and(image, image, mask=plant_mask)\n",
    "\n",
    "#     return plant_segments\n",
    "\n",
    "\n",
    "def segment_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Segments the input image to extract plant regions using adaptive thresholding and morphological operations.\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input RGB image.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The segmented image containing only plant regions.\n",
    "    \"\"\"\n",
    "    # Convert the image from RGB to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Extract the V channel from the HSV image\n",
    "    v_channel = hsv_image[:, :, 2]\n",
    "\n",
    "    # Apply adaptive thresholding (Gaussian method)\n",
    "    plant_mask = cv2.adaptiveThreshold(v_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Define a kernel for morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    # Apply morphological opening to remove noise\n",
    "    plant_mask = cv2.morphologyEx(plant_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Apply morphological closing to fill small holes and smooth boundaries\n",
    "    plant_mask = cv2.morphologyEx(plant_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    plant_segments = cv2.bitwise_and(image, image, mask=plant_mask)\n",
    "\n",
    "    return plant_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_segments = segment_image(rgb_not_norm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(rgb_norm_img, segments, plant_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(rgb_norm_img, segments, plant_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# normalized_images.append(normalized_image)\n",
    "\n",
    "\n",
    "# rgb_images.append(rgb_image)\n",
    "\n",
    "\n",
    "# imgs_segments.append(segments)\n",
    "\n",
    "plant_segments = segment_image(rgb_image)\n",
    "\n",
    "# Replace 'plant_segment_ids' with the list of plant segment IDs\n",
    "masked_image = apply_mask_to_segments(rgb_image, segments, [1])\n",
    "# masked_images.append(masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images, rgb_images, imgs_segments, masked_images = process_images(cropped_fns_rgb[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(normalized_images, rgb_images, imgs_segments, masked_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops, regionprops_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_geometric_features(image):\n",
    "    \"\"\"\n",
    "    Extract geometric features from a binary image of a leaf.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy.ndarray): Binary image of a leaf.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the geometric features.\n",
    "    \"\"\"\n",
    "    props = regionprops(image)\n",
    "    features = pd.DataFrame(regionprops_table(image, properties=('area', 'perimeter', 'eccentricity', 'extent')))\n",
    "    features['aspect_ratio'] = props[0].major_axis_length / props[0].minor_axis_length\n",
    "    features['roundness'] = 4 * np.pi * features['area'] / (features['perimeter'] ** 2)\n",
    "    features['compactness'] = features['area'] / props[0].convex_area\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store the color features\n",
    "mean_colors = np.zeros((segments_fz.max() + 1, 3))  # for mean\n",
    "std_colors = np.zeros((segments_fz.max() + 1, 3))  # for standard deviation\n",
    "\n",
    "# Loop over each segment\n",
    "for segment_id in np.unique(segments_fz):\n",
    "    # Get the pixels of the segment\n",
    "    segment_pixels = img[segments_fz == segment_id]\n",
    "    # Calculate and store the mean and standard deviation of the RGB values of the segment\n",
    "    mean_colors[segment_id] = segment_pixels.mean(axis=0)\n",
    "    std_colors[segment_id] = segment_pixels.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments_qs = quickshift(img_rgb, ratio=0.5, kernel_size=3, max_dist=6, sigma=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (20,20))\n",
    "# plt.imshow(mark_boundaries(img_rgb, segments_qs))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_rp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
