{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../mlai_research/')\n",
    "import log\n",
    "import utils\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from skopt import BayesSearchCV\n",
    "import plotly.express as px\n",
    "import optuna\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, features, target):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe to use.\n",
    "    features (list): The feature column names.\n",
    "    target (str): The target column name.\n",
    "\n",
    "    Returns:\n",
    "    tuple: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train the machine learning model.\n",
    "\n",
    "    Parameters:\n",
    "    model (object): The machine learning model to use.\n",
    "    X_train (pandas.DataFrame): Training features.\n",
    "    y_train (pandas.Series): Training target.\n",
    "\n",
    "    Returns:\n",
    "    object: Trained machine learning model.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the machine learning model and log metrics to MLflow.\n",
    "\n",
    "    Parameters:\n",
    "    model (object): The trained machine learning model.\n",
    "    X_test (pandas.DataFrame): Testing features.\n",
    "    y_test (pandas.Series): Testing target.\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "    # Save confusion matrix as a plot\n",
    "    fig = px.imshow(cm)\n",
    "    fig.write_image(\"confusion_matrix.png\")\n",
    "\n",
    "    # Log confusion matrix to MLflow\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "\n",
    "    # Delete the confusion matrix image file\n",
    "    os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "def run_experiment(df, features, target, model, experiment_name):\n",
    "    \"\"\"\n",
    "    Run a machine learning experiment.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe to use.\n",
    "    features (list): The feature column names.\n",
    "    target (str): The target column name.\n",
    "    model (object): The machine learning model to use.\n",
    "    experiment_name (str): The name of the experiment.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = split_data(df, features, target)\n",
    "\n",
    "    # Start an MLflow experiment\n",
    "    mlflow.start_run(experiment_id=experiment_name)\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = train_model(model, X_train, y_train)\n",
    "\n",
    "    # Evaluate the model and log metrics to MLflow\n",
    "    evaluate_model(trained_model, X_test, y_test)\n",
    "\n",
    "    # End the MLflow run\n",
    "    mlflow.end_run()\n",
    "\n",
    "    return trained_model\n",
    "\n",
    "def hyperparameter_optimization(model, X_train, y_train, search_space):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter optimization using Bayesian optimization.\n",
    "\n",
    "    Parameters:\n",
    "    model (object): The machine learning model to use.\n",
    "    X_train (pandas.DataFrame): Training features.\n",
    "    y_train (pandas.Series): Training target.\n",
    "    search_space (dict): The search space for hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "    dict: Best hyperparameters.\n",
    "    \"\"\"\n",
    "    # Initialize the BayesSearchCV object\n",
    "    bayes_search = BayesSearchCV(model, search_space, n_iter=32, random_state=0)\n",
    "\n",
    "    # Fit the BayesSearchCV object to the data\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = bayes_search.best_params_\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def load_modelling_data(conf):\n",
    "    # Load train data\n",
    "    train_data = np.load(f\"{conf.data.path_mi}{conf.data.fn_train}\")\n",
    "    X_train = train_data['X']\n",
    "    y_train = train_data['y']\n",
    "\n",
    "    # Load validation data\n",
    "    val_data = np.load(f\"{conf.data.path_mi}{conf.data.fn_val}\")\n",
    "    X_val = val_data['X']\n",
    "    y_val = val_data['y']\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20-Dec-23 09:55:56 - INFO - Starting 'load_config'.\n",
      "20-Dec-23 09:55:56 - INFO - Finished 'load_config' in 0.0228 secs.\n"
     ]
    }
   ],
   "source": [
    "conf = utils.load_config(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function to optimize\n",
    "def objective(trial, X_train, y_train):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    \n",
    "    # Create the model with suggested hyperparameters\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3).mean()\n",
    "    return score\n",
    "\n",
    "# Function to run the hyperparameter tuning\n",
    "def run_optuna_tuning():\n",
    "    # Create a study object and specify the direction is 'maximize'.\n",
    "    study = optuna.create_study(direction='maximize', study_name='rf_study', storage='sqlite:///../Users/ashwineekumarpandey/Documents/Academics/Masters/SU_MS_MLAI/Modules/ResearchProject/mlai-research/data/07_model_output/example.db', load_if_exists=True)\n",
    "    \n",
    "    # Optimize the study, the objective function is passed in as the first argument.\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)  # n_jobs=-1 will use all available CPU cores\n",
    "    \n",
    "    # Save the study to a file\n",
    "    joblib.dump(study, '../data/06_models/study.pkl')\n",
    "\n",
    "    # Output the best trial\n",
    "    print('Best trial:')\n",
    "    print(' Value: ', study.best_trial.value)\n",
    "    print(' Params: ')\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data into df, features, target\n",
    "X_train, y_train, X_val, y_val = load_modelling_data(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 1581), (48,), (4, 1581), (4,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 00:33:39,977] A new study created in RDB with name: rf_study\n",
      "[I 2023-12-18 00:33:41,084] Trial 0 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 71, 'max_depth': 19}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2023-12-18 00:33:41,462] Trial 4 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 88, 'max_depth': 16}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2023-12-18 00:33:41,843] Trial 2 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 132, 'max_depth': 9}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:42,106] Trial 3 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 155, 'max_depth': 3}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:42,485] Trial 8 finished with value: 0.8125 and parameters: {'n_estimators': 86, 'max_depth': 6}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:43,055] Trial 11 finished with value: 0.7708333333333334 and parameters: {'n_estimators': 65, 'max_depth': 15}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:43,210] Trial 5 finished with value: 0.8125 and parameters: {'n_estimators': 224, 'max_depth': 5}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:43,442] Trial 7 finished with value: 0.8125 and parameters: {'n_estimators': 253, 'max_depth': 6}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:43,688] Trial 1 finished with value: 0.8125 and parameters: {'n_estimators': 266, 'max_depth': 11}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:43,948] Trial 6 finished with value: 0.8125 and parameters: {'n_estimators': 282, 'max_depth': 19}. Best is trial 2 with value: 0.8333333333333334.\n",
      "[I 2023-12-18 00:33:45,339] Trial 9 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 297, 'max_depth': 19}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:45,488] Trial 10 finished with value: 0.8125 and parameters: {'n_estimators': 274, 'max_depth': 18}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:45,705] Trial 12 finished with value: 0.8125 and parameters: {'n_estimators': 234, 'max_depth': 17}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:45,994] Trial 17 finished with value: 0.8125 and parameters: {'n_estimators': 154, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:46,160] Trial 13 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 233, 'max_depth': 3}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:46,290] Trial 14 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 233, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:46,893] Trial 15 finished with value: 0.8125 and parameters: {'n_estimators': 270, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:47,344] Trial 16 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 274, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:47,491] Trial 18 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 157, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:47,745] Trial 19 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 164, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:47,833] Trial 20 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 152, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:48,626] Trial 22 finished with value: 0.8125 and parameters: {'n_estimators': 189, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:48,870] Trial 21 finished with value: 0.8125 and parameters: {'n_estimators': 194, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:49,015] Trial 23 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 200, 'max_depth': 14}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:49,671] Trial 24 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 203, 'max_depth': 14}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:50,140] Trial 25 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 199, 'max_depth': 14}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:50,183] Trial 26 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 199, 'max_depth': 14}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:50,386] Trial 27 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 197, 'max_depth': 14}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:50,516] Trial 28 finished with value: 0.8125 and parameters: {'n_estimators': 195, 'max_depth': 14}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:51,438] Trial 30 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 206, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:51,512] Trial 29 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 200, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:51,946] Trial 33 finished with value: 0.8125 and parameters: {'n_estimators': 124, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:52,024] Trial 35 finished with value: 0.8125 and parameters: {'n_estimators': 109, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:52,652] Trial 31 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 296, 'max_depth': 7}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:53,675] Trial 32 finished with value: 0.8125 and parameters: {'n_estimators': 294, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:54,191] Trial 34 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 296, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:54,328] Trial 40 finished with value: 0.8125 and parameters: {'n_estimators': 174, 'max_depth': 7}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:54,540] Trial 36 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 299, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:54,894] Trial 41 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 172, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:55,139] Trial 39 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 251, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:55,275] Trial 37 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 299, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:55,420] Trial 38 finished with value: 0.8125 and parameters: {'n_estimators': 294, 'max_depth': 8}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:56,991] Trial 48 finished with value: 0.8125 and parameters: {'n_estimators': 128, 'max_depth': 5}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:56,998] Trial 42 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 251, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:57,222] Trial 49 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 129, 'max_depth': 4}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:57,567] Trial 43 finished with value: 0.8125 and parameters: {'n_estimators': 255, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:57,733] Trial 44 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 245, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:57,910] Trial 45 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 248, 'max_depth': 10}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:58,347] Trial 46 finished with value: 0.8125 and parameters: {'n_estimators': 248, 'max_depth': 20}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:33:58,363] Trial 47 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 224, 'max_depth': 20}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:00,016] Trial 50 finished with value: 0.8125 and parameters: {'n_estimators': 218, 'max_depth': 19}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:00,162] Trial 52 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 218, 'max_depth': 20}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:00,312] Trial 51 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 225, 'max_depth': 19}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:00,612] Trial 53 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 219, 'max_depth': 19}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:00,739] Trial 56 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 163, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:00,892] Trial 54 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 217, 'max_depth': 20}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:01,011] Trial 55 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 219, 'max_depth': 19}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:01,527] Trial 57 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 217, 'max_depth': 17}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:02,218] Trial 58 finished with value: 0.8125 and parameters: {'n_estimators': 146, 'max_depth': 16}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:02,436] Trial 59 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 147, 'max_depth': 16}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:02,490] Trial 60 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 143, 'max_depth': 17}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:02,703] Trial 61 finished with value: 0.7708333333333334 and parameters: {'n_estimators': 144, 'max_depth': 17}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:02,880] Trial 62 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 140, 'max_depth': 16}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:03,128] Trial 63 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 146, 'max_depth': 16}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:03,133] Trial 64 finished with value: 0.8125 and parameters: {'n_estimators': 146, 'max_depth': 17}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:03,783] Trial 65 finished with value: 0.8125 and parameters: {'n_estimators': 147, 'max_depth': 3}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:04,424] Trial 66 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 141, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:04,762] Trial 72 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 112, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:04,945] Trial 68 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 183, 'max_depth': 3}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:05,090] Trial 67 finished with value: 0.8125 and parameters: {'n_estimators': 183, 'max_depth': 4}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:05,117] Trial 69 finished with value: 0.8125 and parameters: {'n_estimators': 181, 'max_depth': 3}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:05,509] Trial 71 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 183, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:05,526] Trial 70 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 182, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:06,006] Trial 75 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 87, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:06,404] Trial 76 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 92, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:06,417] Trial 73 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 184, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:06,610] Trial 77 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 95, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:06,894] Trial 78 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 105, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:07,093] Trial 79 finished with value: 0.8125 and parameters: {'n_estimators': 107, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:07,149] Trial 74 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 187, 'max_depth': 11}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:07,408] Trial 80 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 115, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:07,931] Trial 81 finished with value: 0.8125 and parameters: {'n_estimators': 115, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:08,132] Trial 87 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 52, 'max_depth': 15}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:08,804] Trial 82 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 163, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:08,882] Trial 83 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 165, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:09,091] Trial 84 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 167, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:09,416] Trial 85 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 163, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:09,641] Trial 86 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 167, 'max_depth': 15}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:09,641] Trial 88 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 163, 'max_depth': 13}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:10,377] Trial 92 finished with value: 0.8125 and parameters: {'n_estimators': 95, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:10,447] Trial 89 finished with value: 0.8125 and parameters: {'n_estimators': 164, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:10,456] Trial 93 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 95, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:10,646] Trial 90 finished with value: 0.8541666666666666 and parameters: {'n_estimators': 159, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:10,794] Trial 96 finished with value: 0.7708333333333334 and parameters: {'n_estimators': 74, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:11,347] Trial 97 finished with value: 0.8125 and parameters: {'n_estimators': 76, 'max_depth': 7}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:11,806] Trial 99 finished with value: 0.8125 and parameters: {'n_estimators': 135, 'max_depth': 7}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:11,865] Trial 95 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 208, 'max_depth': 18}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:11,896] Trial 91 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 283, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:12,028] Trial 94 finished with value: 0.8125 and parameters: {'n_estimators': 284, 'max_depth': 9}. Best is trial 9 with value: 0.8541666666666666.\n",
      "[I 2023-12-18 00:34:12,128] Trial 98 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 288, 'max_depth': 12}. Best is trial 9 with value: 0.8541666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value:  0.8541666666666666\n",
      " Params: \n",
      "  n_estimators: 297\n",
      "  max_depth: 19\n"
     ]
    }
   ],
   "source": [
    "# Run the tuning process\n",
    "run_optuna_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the study later\n",
    "loaded_study = joblib.load('../data/06_models/study.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the machine learning model (e.g., SVC)\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter search space\n",
    "# search_space = {\"C\": (1e-6, 1e+6, 'log-uniform'), \"gamma\": (1e-6, 1e+1, 'log-uniform'), \"degree\": (1, 8), \"kernel\": ['linear', 'poly', 'rbf']}\n",
    "search_space = {\"kernel\": ['linear', 'poly', 'rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment with hyperparameter optimization\n",
    "best_params = hyperparameter_optimization(model, X_train, y_train, search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_model = run_experiment(df, features, target, model.set_params(**best_params), \"svc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_rp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
